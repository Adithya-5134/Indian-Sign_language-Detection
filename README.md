# ğŸ¤Ÿ Indian Sign Language Recognition using Deep Learning ğŸ“·

## ğŸ“Œ **Project Overview**
Welcome to the **Indian Sign Language Recognition** project! This deep learning-based system classifies hand gestures into corresponding Indian Sign Language alphabets. It is designed to support communication for the hearing and speech impaired.

## ğŸ“‚ **Dataset Information**

ğŸ“„ **Dataset Source:** Custom Indian Sign Language image dataset  
ğŸ§· **Classes:** Multiple gesture classes representing sign language alphabets

## ğŸ–¼ï¸ **Image Features**

Each image captures a hand gesture representing a specific alphabet. The model learns visual features such as:
- Finger position and orientation  
- Hand contour and shape  
- Background contrast and lighting variations

## ğŸ” **Model Implementation**

ğŸ“œ **File:** PRAICP_1000_IndiSignLang.ipynb

ğŸ› ï¸ **Steps Followed:**
- ğŸ§¹ **Data Preprocessing** â€“ Resizing, normalization, grayscale conversion
- ğŸ“Š **EDA (Exploratory Data Analysis)** â€“ Visualizing class samples and distributions
- ğŸ§  **Model Building** â€“ Custom CNN architecture for multi-class classification
- ğŸ¯ **Model Evaluation** â€“ Accuracy metrics, loss visualization
- ğŸ–ï¸ **Prediction** â€“ Classifying unseen hand gestures in real time or from uploaded images

## ğŸ¤– **Deep Learning Architecture**

- ğŸ“¦ Convolutional Layers for feature extraction
- ğŸŒ€ Max Pooling for spatial reduction
- ğŸ” Flatten + Dense Layers for classification
- ğŸ’§ Dropout for regularization
- ğŸ§  Softmax Activation for multi-class output

## ğŸ“‰ **Metrics Used**

- ğŸ“Œ Training & Validation Accuracy
- ğŸ“Œ Training & Validation Loss
- ğŸ“Œ Confusion Matrix
- ğŸ“Œ Classification Report (Precision, Recall, F1-Score)

## ğŸ§ª **Technologies Used**

- TensorFlow / Keras
- NumPy & Pandas
- OpenCV
- Matplotlib & Seaborn
- Jupyter Notebook

## ğŸ”‘ **Key Insights**

- ğŸ¤– CNN successfully distinguishes between multiple hand gestures.
- ğŸ“ˆ The model shows strong generalization with minimal overfitting.
- ğŸ§ª Effective preprocessing and augmentation improved robustness.

## ğŸ¯ **Conclusion**

This project showcases how deep learning can bridge communication gaps using computer vision. The system can be further enhanced and deployed in educational or assistive tools to support sign language understanding in real-time applications.

---
